# -*- coding: utf-8 -*-
"""Model Time Series IDCAMP 2023

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t0RHLU_klWH413_YWFaQbqNkO2nrRxHL
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import matplotlib.pyplot as plt

df = pd.read_csv('weather_data.csv')

df

df.info()

df

skala = MinMaxScaler()
df_skala = skala.fit_transform(df)

panjang_sekuens = 10
sekuens = []
target = []

for i in range(len(df_skala) - panjang_sekuens):
    sekuens.append(df_skala[i:i+panjang_sekuens])
    target.append(df_skala[i+panjang_sekuens])

X = np.array(sekuens)
y = np.array(target)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Jumlah Data Training Set : {len(X_train)}")
print(f"Jumlah Data Validation Set : {len(X_val)}")

model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(panjang_sekuens, df.shape[1])))
model.add(Dense(df.shape[1]))
model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics="mae")

callbacks = [
    ModelCheckpoint('model-time-series-IDCAMP-2023.keras', save_best_only=True),
]

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=callbacks)

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training dan Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

mae_train = history.history['mae'][-1]
mae_val = history.history['val_mae'][-1]

mae_train_persen = mae_train * 100
mae_val_persen = mae_val * 100

print(f"MAE (Training): {mae_train_persen:.2f}%")

print(f"MAE (Validation): {mae_val_persen:.2f}%")